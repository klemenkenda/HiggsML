{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM ensembles\n",
    "## HiggsML challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interpreter\n",
    "%matplotlib inline\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data, preprocessing and feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding additional feature - missing value: DER_mass_MMC\n",
      "Adding additional feature - missing value: DER_deltaeta_jet_jet\n",
      "Adding additional feature - missing value: DER_mass_jet_jet\n",
      "Adding additional feature - missing value: DER_prodeta_jet_jet\n",
      "Adding additional feature - missing value: DER_lep_eta_centrality\n",
      "Adding additional feature - missing value: PRI_jet_leading_pt\n",
      "Adding additional feature - missing value: PRI_jet_leading_eta\n",
      "Adding additional feature - missing value: PRI_jet_leading_phi\n",
      "Adding additional feature - missing value: PRI_jet_subleading_pt\n",
      "Adding additional feature - missing value: PRI_jet_subleading_eta\n",
      "Adding additional feature - missing value: PRI_jet_subleading_phi\n",
      "Manjkajoči DER_deltaeta_jet_jet\n",
      "Manjkajoči DER_mass_jet_jet\n",
      "Manjkajoči DER_prodeta_jet_jet\n",
      "Manjkajoči DER_lep_eta_centrality\n",
      "Manjkajoči PRI_jet_leading_pt\n",
      "Manjkajoči PRI_jet_leading_eta\n",
      "Manjkajoči PRI_jet_leading_phi\n",
      "Manjkajoči PRI_jet_subleading_pt\n",
      "Manjkajoči PRI_jet_subleading_eta\n",
      "Manjkajoči PRI_jet_subleading_phi\n",
      "$x^2$ DER_mass_MMC\n",
      "$x^2$ DER_mass_transverse_met_lep\n",
      "$x^2$ DER_mass_vis\n",
      "$x^2$ DER_pt_h\n",
      "$x^2$ DER_deltaeta_jet_jet\n",
      "$x^2$ DER_mass_jet_jet\n",
      "$x^2$ DER_prodeta_jet_jet\n",
      "$x^2$ DER_deltar_tau_lep\n",
      "$x^2$ DER_pt_tot\n",
      "$x^2$ DER_sum_pt\n",
      "$x^2$ DER_pt_ratio_lep_tau\n",
      "$x^2$ DER_met_phi_centrality\n",
      "$x^2$ DER_lep_eta_centrality\n",
      "$x^2$ PRI_tau_pt\n",
      "$x^2$ PRI_tau_eta\n",
      "$x^2$ PRI_tau_phi\n",
      "$x^2$ PRI_lep_pt\n",
      "$x^2$ PRI_lep_eta\n",
      "$x^2$ PRI_lep_phi\n",
      "$x^2$ PRI_met\n",
      "$x^2$ PRI_met_phi\n",
      "$x^2$ PRI_met_sumet\n",
      "$x^2$ PRI_jet_num\n",
      "$x^2$ PRI_jet_leading_pt\n",
      "$x^2$ PRI_jet_leading_eta\n",
      "$x^2$ PRI_jet_leading_phi\n",
      "$x^2$ PRI_jet_subleading_pt\n",
      "$x^2$ PRI_jet_subleading_eta\n",
      "$x^2$ PRI_jet_subleading_phi\n",
      "$x^2$ PRI_jet_all_pt\n",
      "$x^2$ - DER_mass_transverse_met_lep\n",
      "$x^2$ - DER_pt_h\n",
      "$x^2$ - DER_deltaeta_jet_jet\n",
      "$x^2$ - DER_mass_jet_jet\n",
      "$x^2$ - DER_prodeta_jet_jet\n",
      "$x^2$ - DER_sum_pt\n",
      "$x^2$ - DER_pt_ratio_lep_tau\n",
      "$x^2$ - DER_met_phi_centrality\n",
      "$x^2$ - DER_lep_eta_centrality\n",
      "$x^2$ - PRI_tau_pt\n",
      "$x^2$ - PRI_tau_eta\n",
      "$x^2$ - PRI_tau_phi\n",
      "$x^2$ - PRI_lep_pt\n",
      "$x^2$ - PRI_lep_eta\n",
      "$x^2$ - PRI_lep_phi\n",
      "$x^2$ - PRI_met_phi\n",
      "$x^2$ - PRI_met_sumet\n",
      "$x^2$ - PRI_jet_num\n",
      "$x^2$ - PRI_jet_leading_pt\n",
      "$x^2$ - PRI_jet_leading_eta\n",
      "$x^2$ - PRI_jet_leading_phi\n",
      "$x^2$ - PRI_jet_subleading_pt\n",
      "$x^2$ - PRI_jet_subleading_eta\n",
      "$x^2$ - PRI_jet_subleading_phi\n",
      "$x^2$ - PRI_jet_all_pt\n",
      "$e^x$ DER_mass_MMC\n",
      "$e^x$ DER_mass_transverse_met_lep\n",
      "$e^x$ DER_mass_vis\n",
      "$e^x$ DER_pt_h\n",
      "$e^x$ DER_deltaeta_jet_jet\n",
      "$e^x$ DER_mass_jet_jet\n",
      "$e^x$ DER_prodeta_jet_jet\n",
      "$e^x$ DER_deltar_tau_lep\n",
      "$e^x$ DER_pt_tot\n",
      "$e^x$ DER_sum_pt\n",
      "$e^x$ DER_pt_ratio_lep_tau\n",
      "$e^x$ DER_met_phi_centrality\n",
      "$e^x$ DER_lep_eta_centrality\n",
      "$e^x$ PRI_tau_pt\n",
      "$e^x$ PRI_tau_eta\n",
      "$e^x$ PRI_tau_phi\n",
      "$e^x$ PRI_lep_pt\n",
      "$e^x$ PRI_lep_eta\n",
      "$e^x$ PRI_lep_phi\n",
      "$e^x$ PRI_met\n",
      "$e^x$ PRI_met_phi\n",
      "$e^x$ PRI_met_sumet\n",
      "$e^x$ PRI_jet_num\n",
      "$e^x$ PRI_jet_leading_pt\n",
      "$e^x$ PRI_jet_leading_eta\n",
      "$e^x$ PRI_jet_leading_phi\n",
      "$e^x$ PRI_jet_subleading_pt\n",
      "$e^x$ PRI_jet_subleading_eta\n",
      "$e^x$ PRI_jet_subleading_phi\n",
      "$e^x$ PRI_jet_all_pt\n",
      "$e^x$ - DER_mass_MMC\n",
      "$e^x$ - DER_mass_transverse_met_lep\n",
      "$e^x$ - DER_mass_vis\n",
      "$e^x$ - DER_pt_h\n",
      "$e^x$ - DER_deltaeta_jet_jet\n",
      "$e^x$ - DER_mass_jet_jet\n",
      "$e^x$ - DER_prodeta_jet_jet\n",
      "$e^x$ - DER_deltar_tau_lep\n",
      "$e^x$ - DER_pt_tot\n",
      "$e^x$ - DER_pt_ratio_lep_tau\n",
      "$e^x$ - DER_met_phi_centrality\n",
      "$e^x$ - DER_lep_eta_centrality\n",
      "$e^x$ - PRI_tau_pt\n",
      "$e^x$ - PRI_tau_eta\n",
      "$e^x$ - PRI_tau_phi\n",
      "$e^x$ - PRI_lep_pt\n",
      "$e^x$ - PRI_lep_eta\n",
      "$e^x$ - PRI_lep_phi\n",
      "$e^x$ - PRI_met\n",
      "$e^x$ - PRI_met_phi\n",
      "$e^x$ - PRI_jet_num\n",
      "$e^x$ - PRI_jet_leading_pt\n",
      "$e^x$ - PRI_jet_leading_eta\n",
      "$e^x$ - PRI_jet_leading_phi\n",
      "$e^x$ - PRI_jet_subleading_pt\n",
      "$e^x$ - PRI_jet_subleading_eta\n",
      "$e^x$ - PRI_jet_subleading_phi\n",
      "$e^x$ - PRI_jet_all_pt\n",
      "$\\sqrt{x}$ DER_mass_MMC\n",
      "$\\sqrt{x}$ DER_mass_transverse_met_lep\n",
      "$\\sqrt{x}$ DER_mass_vis\n",
      "$\\sqrt{x}$ DER_pt_h\n",
      "$\\sqrt{x}$ DER_deltaeta_jet_jet\n",
      "$\\sqrt{x}$ DER_mass_jet_jet\n",
      "$\\sqrt{x}$ DER_prodeta_jet_jet\n",
      "$\\sqrt{x}$ DER_deltar_tau_lep\n",
      "$\\sqrt{x}$ DER_pt_tot\n",
      "$\\sqrt{x}$ DER_sum_pt\n",
      "$\\sqrt{x}$ DER_pt_ratio_lep_tau\n",
      "$\\sqrt{x}$ DER_met_phi_centrality\n",
      "$\\sqrt{x}$ DER_lep_eta_centrality\n",
      "$\\sqrt{x}$ PRI_tau_pt\n",
      "$\\sqrt{x}$ PRI_tau_eta\n",
      "$\\sqrt{x}$ PRI_tau_phi\n",
      "$\\sqrt{x}$ PRI_lep_pt\n",
      "$\\sqrt{x}$ PRI_lep_eta\n",
      "$\\sqrt{x}$ PRI_lep_phi\n",
      "$\\sqrt{x}$ PRI_met\n",
      "$\\sqrt{x}$ PRI_met_phi\n",
      "$\\sqrt{x}$ PRI_met_sumet\n",
      "$\\sqrt{x}$ PRI_jet_num\n",
      "$\\sqrt{x}$ PRI_jet_leading_pt\n",
      "$\\sqrt{x}$ PRI_jet_leading_eta\n",
      "$\\sqrt{x}$ PRI_jet_leading_phi\n",
      "$\\sqrt{x}$ PRI_jet_subleading_pt\n",
      "$\\sqrt{x}$ PRI_jet_subleading_eta\n",
      "$\\sqrt{x}$ PRI_jet_subleading_phi\n",
      "$\\sqrt{x}$ PRI_jet_all_pt\n",
      "$\\sqrt{x}$ - DER_mass_transverse_met_lep\n",
      "$\\sqrt{x}$ - DER_pt_h\n",
      "$\\sqrt{x}$ - DER_deltaeta_jet_jet\n",
      "$\\sqrt{x}$ - DER_mass_jet_jet\n",
      "$\\sqrt{x}$ - DER_prodeta_jet_jet\n",
      "$\\sqrt{x}$ - DER_pt_tot\n",
      "$\\sqrt{x}$ - DER_sum_pt\n",
      "$\\sqrt{x}$ - DER_met_phi_centrality\n",
      "$\\sqrt{x}$ - DER_lep_eta_centrality\n",
      "$\\sqrt{x}$ - PRI_tau_pt\n",
      "$\\sqrt{x}$ - PRI_tau_eta\n",
      "$\\sqrt{x}$ - PRI_tau_phi\n",
      "$\\sqrt{x}$ - PRI_lep_pt\n",
      "$\\sqrt{x}$ - PRI_lep_eta\n",
      "$\\sqrt{x}$ - PRI_lep_phi\n",
      "$\\sqrt{x}$ - PRI_met_phi\n",
      "$\\sqrt{x}$ - PRI_met_sumet\n",
      "$\\sqrt{x}$ - PRI_jet_num\n",
      "$\\sqrt{x}$ - PRI_jet_leading_pt\n",
      "$\\sqrt{x}$ - PRI_jet_leading_eta\n",
      "$\\sqrt{x}$ - PRI_jet_leading_phi\n",
      "$\\sqrt{x}$ - PRI_jet_subleading_pt\n",
      "$\\sqrt{x}$ - PRI_jet_subleading_eta\n",
      "$\\sqrt{x}$ - PRI_jet_subleading_phi\n",
      "$\\sqrt{x}$ - PRI_jet_all_pt\n"
     ]
    }
   ],
   "source": [
    "# LOADING\n",
    "dirName = '../../data/'\n",
    "fileName = dirName + 'training.csv'\n",
    "data = pd.read_csv(fileName)\n",
    "\n",
    "# PREPROCESSING\n",
    "# replace missing values with NaN\n",
    "data = data.replace(-999.0, np.nan)\n",
    "\n",
    "# learning data\n",
    "X = data.copy()\n",
    "del X['EventId']\n",
    "del X['Weight']\n",
    "del X['Label']\n",
    "y = data['Label']\n",
    "w = data['Weight']\n",
    "\n",
    "# replace missing values with NaN\n",
    "X = X.replace(-999.0, np.nan)\n",
    "\n",
    "# missing_values is the value of your placeholder, strategy is if you'd like mean, median or mode, and axis=0 means it calculates the imputation based on the other feature values for that sample\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X)\n",
    "Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)\n",
    "missingX = imp.transform(X)\n",
    "\n",
    "# scale for feature generation\n",
    "def scale():\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    missingX_scaled = scaler.fit_transform(missingX)\n",
    "    return missingX_scaled\n",
    "\n",
    "\n",
    "missingX_scaled = scale()\n",
    "\n",
    "# FEATURE GENERATION\n",
    "# (8) from the thesis\n",
    "\n",
    "# 1 - take original missingX\n",
    "# 2 - add features based on X and missingX\n",
    "# 3 - perform scaling\n",
    "# 4 - use original code above (make sets + SVM)\n",
    "\n",
    "# remember original missingX\n",
    "originalMissingX = missingX.copy()\n",
    "\n",
    "# add missing value information (1 present, 0 missing)\n",
    "# functions\n",
    "def hasNaN(name):\n",
    "    values = list(np.isnan(X[name]).values)\n",
    "    for i in values:\n",
    "        if (i == True):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def addMissing():\n",
    "    missX = missingX.copy()\n",
    "    cols = list(X.columns.values)\n",
    "    for col in cols:\n",
    "        if hasNaN(col):\n",
    "            print('Adding additional feature - missing value:', col)\n",
    "            myCol = np.isnan(X[col]).map({True: 1, False: 0})\n",
    "            missX = np.c_[missX, myCol]\n",
    "            additionalNames.append(\"Manjkajoči \" + col)\n",
    "    return(missX)\n",
    "\n",
    "# FG - missing\n",
    "missingX = originalMissingX.copy();\n",
    "# add columns with missing number\n",
    "additionalNames = [];\n",
    "missX = addMissing()\n",
    "# write to the table\n",
    "missingX = missX.copy()\n",
    "def filterMissing(relevantMissing):\n",
    "    missX = missingX.copy()\n",
    "    newAdditionalNames = []\n",
    "    deletedN = 0\n",
    "    for x in additionalNames:\n",
    "        if not (x in relevantMissing):\n",
    "            nIndex = additionalNames.index(x) - deletedN\n",
    "            aIndex = nIndex + 30 # we are keeping original features\n",
    "            print(x)\n",
    "            \n",
    "            # remove column\n",
    "            missX = np.delete(missX, aIndex, 1)\n",
    "            deletedN = deletedN + 1\n",
    "        else:\n",
    "            newAdditionalNames.append(x)\n",
    "                \n",
    "    return(missX, newAdditionalNames)\n",
    "\n",
    "# filter only relevant features\n",
    "relevantMissing = ['Manjkajoči DER_mass_MMC']\n",
    "missingX, additionalNames = filterMissing(relevantMissing)\n",
    "\n",
    "\n",
    "# FG - x^2\n",
    "# add columns with x^2\n",
    "def x2kernel(x):\n",
    "    return(x*x)\n",
    "def addOneX(name, kernel):\n",
    "    missX = missingX.copy()\n",
    "    cols = list(X.columns.values)\n",
    "    i = 0\n",
    "    for col in cols:\n",
    "        myCol = kernel(missingX[:,i])\n",
    "        print(name + ' ' + col)\n",
    "        missX = np.c_[missX, myCol]\n",
    "        additionalNames.append(name + \" - \" + col)\n",
    "        i = i + 1\n",
    "    return(missX)\n",
    "\n",
    "def addOneXNormalized(name, kernel):\n",
    "    missX = missingX.copy()\n",
    "    cols = list(X.columns.values)\n",
    "    i = 0\n",
    "    for col in cols:\n",
    "        myCol = kernel(missingX_scaled[:,i])\n",
    "        print(name + ' ' + col)\n",
    "        missX = np.c_[missX, myCol]\n",
    "        additionalNames.append(name + \" - \" + col)\n",
    "        i = i + 1\n",
    "    return(missX)\n",
    "missX = addOneX('$x^2$', x2kernel)\n",
    "missingX = missX.copy()\n",
    "# filter only relevant features\n",
    "relevantMissing = relevantMissing + ['$x^2$ - DER_mass_MMC',\n",
    " '$x^2$ - DER_mass_vis',\n",
    " '$x^2$ - DER_deltar_tau_lep',\n",
    " '$x^2$ - DER_pt_tot',\n",
    " '$x^2$ - PRI_met']\n",
    "missingX, additionalNames = filterMissing(relevantMissing)\n",
    "\n",
    "\n",
    "\n",
    "# FG - e^x\n",
    "# add columns with e^x\n",
    "def exkernel(x):\n",
    "    return(np.exp(x))\n",
    "missX = addOneXNormalized('$e^x$', exkernel)\n",
    "missingX = missX.copy()\n",
    "# filter only relevant features\n",
    "relevantMissing = relevantMissing + ['$e^x$ - DER_sum_pt', '$e^x$ - PRI_met_sumet']\n",
    "missingX, additionalNames = filterMissing(relevantMissing)\n",
    "\n",
    "\n",
    "# FG - sqrt(x)\n",
    "# add columns with sqrt(x)\n",
    "def sqrtkernel(x):\n",
    "    xArray = []\n",
    "    for val in x:\n",
    "        if (val > 0):\n",
    "            xArray.append(np.sqrt(val))\n",
    "        else:\n",
    "            xArray.append(-np.sqrt(-val))\n",
    "    return xArray;\n",
    "missX = addOneX('$\\sqrt{x}$', sqrtkernel)\n",
    "missingX = missX.copy()\n",
    "# filter only relevant features\n",
    "relevantMissing = relevantMissing + ['$\\\\sqrt{x}$ - DER_mass_MMC',\n",
    " '$\\\\sqrt{x}$ - DER_mass_vis',\n",
    " '$\\\\sqrt{x}$ - DER_deltar_tau_lep',\n",
    " '$\\\\sqrt{x}$ - DER_pt_ratio_lep_tau',\n",
    " '$\\\\sqrt{x}$ - PRI_met']\n",
    "missingX, additionalNames = filterMissing(relevantMissing)\n",
    "\n",
    "\n",
    "# FINAL SCALING\n",
    "# scale the data for SVM\n",
    "\n",
    "missingX_scaled = scale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use - binary classification result\n",
    "## Learn and save 9 SVM models\n",
    "25k lines to learn EACH; \n",
    "Use RBF(8) - most successful from the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "# compute AMS\n",
    "def ams(s, b):\n",
    "    from math import sqrt,log\n",
    "    if b==0:\n",
    "        return 0\n",
    "\n",
    "    return sqrt(2*((s+b+10)*log(1+float(s)/(b+10))-s))\n",
    "\n",
    "# compute all measures\n",
    "def validate(predicted, real, weights):\n",
    "    sumsig = 0.\n",
    "    sumbkg = 0.\n",
    "    tp = 0.\n",
    "    tn = 0.\n",
    "    fp = 0.\n",
    "    fn = 0.\n",
    "    precision = 0.\n",
    "    recall = 0.\n",
    "    acc = 0.\n",
    "    \n",
    "    if (predicted.shape[0] != real.shape[0]):\n",
    "        raise Exception\n",
    "    \n",
    "    for i in range(predicted.shape[0]):\n",
    "        if predicted[i] == \"s\":\n",
    "            if real[i] == \"s\":\n",
    "                sumsig += weights[i]\n",
    "                tp += 1\n",
    "            else:\n",
    "                sumbkg += weights[i]\n",
    "                fp += 1\n",
    "        else:\n",
    "            if real[i] == \"s\":\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    \n",
    "    print(tp, fp, fn, tn)\n",
    "    \n",
    "    # calculate scores\n",
    "    amsscore = ams(sumsig * 10, sumbkg * 10)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "    f1score = (2 * precision * recall)/(precision + recall)\n",
    "\n",
    "    printScores(tp, tn, fp, fn, precision, recall, acc, f1score, amsscore)\n",
    "    \n",
    "    return amsscore\n",
    "\n",
    "def printScores(tp, tn, fp, fn, precision, recall, acc, f1score, amsscore):\n",
    "    all = tp + tn + fp + fn\n",
    "    print(tp/all * 100, tn/all * 100, fp/all * 100, fn/all * 100)\n",
    "    print(precision, recall, acc, f1score)\n",
    "    print(amsscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  0\n",
      "[LibSVM]6098.0 1834.0 2511.0 14557.0\n",
      "24.392 58.228 7.335999999999999 10.044\n",
      "0.7687846696923852 0.7083284934371007 0.8262 0.7373193881869293\n",
      "2.7843998235755807\n",
      "-----------\n",
      "Model  1\n",
      "[LibSVM]6086.0 1784.0 2523.0 14607.0\n",
      "24.343999999999998 58.428000000000004 7.136000000000001 10.091999999999999\n",
      "0.7733163913595934 0.7069346033221048 0.82772 0.7386370532192488\n",
      "2.831280085527397\n",
      "-----------\n",
      "Model  2\n",
      "[LibSVM]5998.0 1706.0 2611.0 14685.0\n",
      "23.992 58.74 6.824 10.444\n",
      "0.7785565939771547 0.6967127424788012 0.82732 0.7353644332740759\n",
      "2.8526817064556647\n",
      "-----------\n",
      "Model  3\n",
      "[LibSVM]6099.0 1819.0 2510.0 14572.0\n",
      "24.396 58.288 7.276000000000001 10.040000000000001\n",
      "0.7702702702702703 0.7084446509466837 0.82684 0.7380649845707026\n",
      "2.7485440921925\n",
      "-----------\n",
      "Model  4\n",
      "[LibSVM]6021.0 1697.0 2588.0 14694.0\n",
      "24.084 58.775999999999996 6.787999999999999 10.352\n",
      "0.7801243845555843 0.6993843651992101 0.8286 0.7375512954002572\n",
      "2.8416114891935025\n",
      "-----------\n",
      "Model  5\n",
      "[LibSVM]6017.0 1713.0 2592.0 14678.0\n",
      "24.068 58.711999999999996 6.851999999999999 10.367999999999999\n",
      "0.7783958602846054 0.6989197351608781 0.8278 0.7365199828630883\n",
      "2.839328299938631\n",
      "-----------\n",
      "Model  6\n",
      "[LibSVM]6101.0 1832.0 2508.0 14559.0\n",
      "24.404 58.236 7.327999999999999 10.032\n",
      "0.7690659271397958 0.7086769659658497 0.8264 0.7376375287147867\n",
      "2.8094993096341865\n",
      "-----------\n",
      "Model  7\n",
      "[LibSVM]6028.0 1801.0 2581.0 14590.0\n",
      "24.112000000000002 58.36 7.204000000000001 10.324\n",
      "0.7699578490228637 0.7001974677662911 0.82472 0.7334225574887456\n",
      "2.761895535767005\n",
      "-----------\n",
      "Model  8\n",
      "[LibSVM]6013.0 1768.0 2596.0 14623.0\n",
      "24.052 58.492 7.072000000000001 10.384\n",
      "0.7727798483485413 0.6984551051225462 0.82544 0.7337400854179379\n",
      "2.7691057883606605\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# make test dataset\n",
    "Xtest = Xtest = missingX_scaled[-25000:]\n",
    "ytest = ytest = y[-25000:]\n",
    "wtest = w[-25000:]\n",
    "\n",
    "# learnSVM, n = model number 1-9\n",
    "def learnSVM(n):\n",
    "    # number of samples per model\n",
    "    numSamples = 25000\n",
    "    \n",
    "    # define dataset\n",
    "    startOffset = (n) * numSamples + 1\n",
    "    endOffset = startOffset + numSamples\n",
    "    \n",
    "    Xtrain = missingX_scaled[startOffset:endOffset]\n",
    "    ytrain = y[startOffset:endOffset]\n",
    "    wtrain = w[startOffset:endOffset]\n",
    "    ytrainVals = ytrain.replace(to_replace=['s','b'],value=[1,0])\n",
    "    \n",
    "    # start learning\n",
    "    C = 1.0\n",
    "    # SVM RBF\n",
    "    clf = svm.SVC(verbose=1)\n",
    "    clf.fit(Xtrain, ytrainVals)\n",
    "    \n",
    "    return clf;\n",
    "\n",
    "# validation\n",
    "def validateModel(clf):\n",
    "    predicted = clf.predict(Xtest)\n",
    "    predictedV = pd.Series(predicted).map({1: 's', 0: 'b'})\n",
    "    validate(predictedV, np.array(ytest), np.array(wtest))\n",
    "\n",
    "# save model\n",
    "def saveModel(name, n, clf):\n",
    "    joblib.dump(clf, name + '-' + str(n) + '.pkl') \n",
    "\n",
    "# learin all 9 models\n",
    "clfs = []\n",
    "def learnAllSVMs():\n",
    "    for i in range(9):\n",
    "        print(\"Model \", i)\n",
    "        clfs.append(learnSVM(i))\n",
    "        validateModel(clfs[i])\n",
    "        saveModel(\"SVM8\", i, clfs[i])\n",
    "        print(\"-----------\")\n",
    "\n",
    "learnAllSVMs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating Model 0\n",
      "Validating Model 1\n",
      "Validating Model 2\n",
      "Validating Model 3\n",
      "Validating Model 4\n",
      "Validating Model 5\n",
      "Validating Model 6\n",
      "Validating Model 7\n",
      "Validating Model 8\n"
     ]
    }
   ],
   "source": [
    "# validation with voting\n",
    "def validateEnsembleVoting(clfs):\n",
    "    N = len(clfs)\n",
    "    for i in range(N):\n",
    "        print('Validating Model', i)\n",
    "        predicted = clfs[i].predict(Xtest)\n",
    "        predictedV = pd.Series(predicted)\n",
    "        if (i == 0):\n",
    "            votes = predictedV.copy();\n",
    "        else:\n",
    "            votes = np.c_[votes, predictedV]\n",
    "    \n",
    "    # voting count\n",
    "    predictedAll = pd.Series(np.mean(votes, axis=1)>0.5).map({True: 's', False: 'b'})\n",
    "    validate(predictedAll, np.array(ytest), np.array(wtest))\n",
    "    \n",
    "    return(votes)\n",
    "    \n",
    "votes = validateEnsembleVoting(clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6099.0 1719.0 2510.0 14672.0\n",
      "24.396 58.687999999999995 6.876 10.040000000000001\n",
      "0.7801227935533385 0.7084446509466837 0.83084 0.7425579838071467\n",
      "2.853868020219204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.853868020219204"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedAll = pd.Series(np.mean(votes, axis=1)>0.5).map({True: 's', False: 'b'})\n",
    "validate(predictedAll, np.array(ytest), np.array(wtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascade classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating Model 0\n",
      "Validating Model 1\n",
      "Validating Model 2\n",
      "Validating Model 3\n",
      "Validating Model 4\n",
      "Validating Model 5\n",
      "Validating Model 6\n",
      "Validating Model 7\n",
      "Validating Model 8\n",
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def learnMetaSVM(clfs):\n",
    "    # number of samples per model\n",
    "    numSamples = 225000\n",
    "    \n",
    "    # define dataset\n",
    "    startOffset = 1\n",
    "    endOffset = numSamples\n",
    "    \n",
    "    Xtrain = missingX_scaled[startOffset:endOffset]\n",
    "    ytrain = y[startOffset:endOffset]\n",
    "    wtrain = w[startOffset:endOffset]\n",
    "    ytrainVals = ytrain.replace(to_replace=['s','b'],value=[1,0])\n",
    "    \n",
    "    # create training set for meta classifier\n",
    "    N = len(clfs)\n",
    "    for i in range(N):\n",
    "        print('Calculating Model', i)\n",
    "        predicted = clfs[i].predict(Xtrain)\n",
    "        predictedV = pd.Series(predicted)\n",
    "        if (i == 0):\n",
    "            Xvotes = predictedV.copy();\n",
    "        else:\n",
    "            Xvotes = np.c_[Xvotes, predictedV]\n",
    "    \n",
    "    # create meta classifier\n",
    "    clf = svm.SVC(verbose=1)\n",
    "    clf.fit(Xvotes, ytrainVals)\n",
    "    \n",
    "    return clf;\n",
    "\n",
    "metaclf = learnMetaSVM(clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# validation of cascade model\n",
    "def validateCascadeModel(clf):\n",
    "    predicted = clf.predict(votes)\n",
    "    predictedV = pd.Series(predicted).map({1: 's', 0: 'b'})\n",
    "    validate(predictedV, np.array(ytest), np.array(wtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hack - DO NOT USE!!!\n",
    "metaclf = Out[53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6109.0 1761.0 2500.0 14630.0\n",
      "24.436 58.52 7.0440000000000005 10.0\n",
      "0.7762388818297332 0.7096062260425137 0.82956 0.7414284847381516\n",
      "2.842482295918227\n"
     ]
    }
   ],
   "source": [
    "validateCascadeModel(metaclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(25000, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(25000, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
