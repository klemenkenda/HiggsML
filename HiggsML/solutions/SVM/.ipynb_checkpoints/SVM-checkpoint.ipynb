{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "## HiggsML Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirName = '../../data/'\n",
    "fileName = dirName + 'training.csv'\n",
    "data = pd.read_csv(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace missing values with NaN\n",
    "# data = data.replace(-999.0, np.nan)\n",
    "\n",
    "# learning data\n",
    "X = data.copy()\n",
    "del X['EventId']\n",
    "del X['Weight']\n",
    "del X['Label']\n",
    "y = data['Label']\n",
    "w = data['Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# handle missing values\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# replace missing values with NaN\n",
    "# X = X.replace(-999.0, np.nan)\n",
    "\n",
    "# missing_values is the value of your placeholder, strategy is if you'd like mean, median or mode, and axis=0 means it calculates the imputation based on the other feature values for that sample\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X)\n",
    "Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)\n",
    "missingX = imp.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testing SVM\n",
    "missingX = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Training set to real training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = missingX[1:225000]\n",
    "Xtest = missingX[-25000:]\n",
    "ytrain = y[1:225000]\n",
    "ytest = y[-25000:]\n",
    "wtrain = w[1:225000]\n",
    "wtest = w[-25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minimal subset for faster learning of SVM.fit\n",
    "Xtrain = missingX[1:225000]\n",
    "ytrain = y[1:225000]\n",
    "wtrain = w[1:225000]\n",
    "ytrainVals = ytrain.replace(to_replace=['s','b'],value=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC(verbose=1)\n",
    "clf.fit(Xtrain, ytrainVals, sample_weight=wtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(probability=True, verbose=1)\n",
    "clf.fit(Xtrain, ytrainVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2128           31.48s\n",
      "         2           1.1659           30.14s\n",
      "         3           1.1184           29.40s\n",
      "         4           1.0764           28.68s\n",
      "         5           1.0441           28.32s\n",
      "         6           1.0134           27.54s\n",
      "         7           0.9870           26.84s\n",
      "         8           0.9666           26.09s\n",
      "         9           0.9436           25.47s\n",
      "        10           0.9248           24.79s\n",
      "        20           0.8184           18.46s\n",
      "        30           0.7757           12.11s\n",
      "        40           0.7536            5.99s\n",
      "        50           0.7396            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=5, max_features=10, max_leaf_nodes=None,\n",
       "              min_samples_leaf=200, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=1,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradint Boosting to test WTF is wrong\n",
    "clf = GBC(n_estimators=50, max_depth=5,min_samples_leaf=200,max_features=10,verbose=1)\n",
    "clf.fit(Xtrain,ytrainVals) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute AMS\n",
    "def ams(s, b):\n",
    "    from math import sqrt,log\n",
    "    if b==0:\n",
    "        return 0\n",
    "\n",
    "    return sqrt(2*((s+b+10)*log(1+float(s)/(b+10))-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute all measures\n",
    "def validate(predicted, real, weights):\n",
    "    sumsig = 0.\n",
    "    sumbkg = 0.\n",
    "    tp = 0.\n",
    "    tn = 0.\n",
    "    fp = 0.\n",
    "    fn = 0.\n",
    "    precision = 0.\n",
    "    recall = 0.\n",
    "    acc = 0.\n",
    "    \n",
    "    if (predicted.shape[0] != real.shape[0]):\n",
    "        raise Exception\n",
    "    \n",
    "    for i in range(predicted.shape[0]):\n",
    "        if predicted[i] == \"s\":\n",
    "            if real[i] == \"s\":\n",
    "                sumsig += weights[i]\n",
    "                tp += 1\n",
    "            else:\n",
    "                sumbkg += weights[i]\n",
    "                fp += 1\n",
    "        else:\n",
    "            if real[i] == \"s\":\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    \n",
    "    print(tp, fp, fn, tn)\n",
    "    \n",
    "    # calculate scores\n",
    "    amsscore = ams(sumsig * 10, sumbkg * 10)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "    f1score = (2 * precision * recall)/(precision + recall)\n",
    "\n",
    "    printScores(tp, tn, fp, fn, precision, recall, acc, f1score, amsscore)\n",
    "    \n",
    "    return amsscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printScores(tp, tn, fp, fn, precision, recall, acc, f1score, amsscore):\n",
    "    all = tp + tn + fp + fn\n",
    "    print(\"TP: \", tp/all)\n",
    "    print(\"TN: \", tn/all)\n",
    "    print(\"FP: \", fp/all)\n",
    "    print(\"FN: \", fn/all)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Acc: \", acc)\n",
    "    print(\"F1: \", f1score)\n",
    "    print(\"AMS: \", amsscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "predicted = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictedV = pd.Series(predicted).map({1: 's', 0: 'b'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136.0 1707.0 2473.0 14684.0\n",
      "TP:  0.24544\n",
      "TN:  0.58736\n",
      "FP:  0.06828\n",
      "FN:  0.09892\n",
      "Precision:  0.7823536911895959\n",
      "Recall:  0.7127424788012545\n",
      "Acc:  0.8328\n",
      "F1:  0.7459275468028203\n",
      "AMS:  2.8057784356183713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.8057784356183713"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(predictedV, np.array(ytest), np.array(wtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vars = clf.predict_proba(Xtest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = vars - vars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3321973 ,  0.3321982 ,  0.3321982 ,  0.3321982 ,  0.3321982 ,\n",
       "        0.3321982 ,  0.3321982 ,  0.3321982 ,  0.33220401,  0.3321982 ,\n",
       "        0.33219092,  0.3321982 ,  0.3321982 ,  0.33218499,  0.3290364 ,\n",
       "        0.3321982 ,  0.3321982 ,  0.3321982 ,  0.3321982 ])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
