{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiggsML\n",
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using XGBoost official demo for kaggle-higgs\n",
    "# https://github.com/dmlc/xgboost/blob/master/demo/kaggle-higgs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading from csv \n",
      "weight statistics: wpos=1522.38, wneg=905021, ratio=594.478\n",
      "loading data end, start to boost trees\n",
      "[0]\ttrain-auc:0.911423\ttrain-ams@0.15:3.82749\n",
      "[1]\ttrain-auc:0.915852\ttrain-ams@0.15:3.84539\n",
      "[2]\ttrain-auc:0.918686\ttrain-ams@0.15:4.13342\n",
      "[3]\ttrain-auc:0.919729\ttrain-ams@0.15:4.04069\n",
      "[4]\ttrain-auc:0.920828\ttrain-ams@0.15:4.2107\n",
      "[5]\ttrain-auc:0.921371\ttrain-ams@0.15:4.22123\n",
      "[6]\ttrain-auc:0.921817\ttrain-ams@0.15:4.22617\n",
      "[7]\ttrain-auc:0.923193\ttrain-ams@0.15:4.32661\n",
      "[8]\ttrain-auc:0.923809\ttrain-ams@0.15:4.33708\n",
      "[9]\ttrain-auc:0.924416\ttrain-ams@0.15:4.34483\n",
      "[10]\ttrain-auc:0.924974\ttrain-ams@0.15:4.37694\n",
      "[11]\ttrain-auc:0.925546\ttrain-ams@0.15:4.40831\n",
      "[12]\ttrain-auc:0.926095\ttrain-ams@0.15:4.42525\n",
      "[13]\ttrain-auc:0.926513\ttrain-ams@0.15:4.44384\n",
      "[14]\ttrain-auc:0.926951\ttrain-ams@0.15:4.48167\n",
      "[15]\ttrain-auc:0.927612\ttrain-ams@0.15:4.53498\n",
      "[16]\ttrain-auc:0.928051\ttrain-ams@0.15:4.5426\n",
      "[17]\ttrain-auc:0.928689\ttrain-ams@0.15:4.58298\n",
      "[18]\ttrain-auc:0.929227\ttrain-ams@0.15:4.61408\n",
      "[19]\ttrain-auc:0.929743\ttrain-ams@0.15:4.67766\n",
      "[20]\ttrain-auc:0.930084\ttrain-ams@0.15:4.6826\n",
      "[21]\ttrain-auc:0.930529\ttrain-ams@0.15:4.70597\n",
      "[22]\ttrain-auc:0.930865\ttrain-ams@0.15:4.75961\n",
      "[23]\ttrain-auc:0.931232\ttrain-ams@0.15:4.7486\n",
      "[24]\ttrain-auc:0.931558\ttrain-ams@0.15:4.8004\n",
      "[25]\ttrain-auc:0.932007\ttrain-ams@0.15:4.80993\n",
      "[26]\ttrain-auc:0.932336\ttrain-ams@0.15:4.81878\n",
      "[27]\ttrain-auc:0.932658\ttrain-ams@0.15:4.8477\n",
      "[28]\ttrain-auc:0.933018\ttrain-ams@0.15:4.86501\n",
      "[29]\ttrain-auc:0.933358\ttrain-ams@0.15:4.89488\n",
      "[30]\ttrain-auc:0.933679\ttrain-ams@0.15:4.90582\n",
      "[31]\ttrain-auc:0.934\ttrain-ams@0.15:4.93808\n",
      "[32]\ttrain-auc:0.934279\ttrain-ams@0.15:4.94736\n",
      "[33]\ttrain-auc:0.934656\ttrain-ams@0.15:4.9606\n",
      "[34]\ttrain-auc:0.934985\ttrain-ams@0.15:4.98815\n",
      "[35]\ttrain-auc:0.935262\ttrain-ams@0.15:5.02229\n",
      "[36]\ttrain-auc:0.93563\ttrain-ams@0.15:5.04088\n",
      "[37]\ttrain-auc:0.935886\ttrain-ams@0.15:5.0528\n",
      "[38]\ttrain-auc:0.936175\ttrain-ams@0.15:5.06672\n",
      "[39]\ttrain-auc:0.936434\ttrain-ams@0.15:5.08874\n",
      "[40]\ttrain-auc:0.936679\ttrain-ams@0.15:5.08607\n",
      "[41]\ttrain-auc:0.936947\ttrain-ams@0.15:5.11547\n",
      "[42]\ttrain-auc:0.937129\ttrain-ams@0.15:5.13905\n",
      "[43]\ttrain-auc:0.937349\ttrain-ams@0.15:5.16674\n",
      "[44]\ttrain-auc:0.937567\ttrain-ams@0.15:5.19398\n",
      "[45]\ttrain-auc:0.937772\ttrain-ams@0.15:5.22352\n",
      "[46]\ttrain-auc:0.937988\ttrain-ams@0.15:5.24882\n",
      "[47]\ttrain-auc:0.938157\ttrain-ams@0.15:5.27441\n",
      "[48]\ttrain-auc:0.938382\ttrain-ams@0.15:5.29941\n",
      "[49]\ttrain-auc:0.938577\ttrain-ams@0.15:5.32444\n",
      "[50]\ttrain-auc:0.938779\ttrain-ams@0.15:5.3646\n",
      "[51]\ttrain-auc:0.938899\ttrain-ams@0.15:5.35943\n",
      "[52]\ttrain-auc:0.939054\ttrain-ams@0.15:5.37231\n",
      "[53]\ttrain-auc:0.939295\ttrain-ams@0.15:5.38737\n",
      "[54]\ttrain-auc:0.939504\ttrain-ams@0.15:5.43614\n",
      "[55]\ttrain-auc:0.939674\ttrain-ams@0.15:5.44824\n",
      "[56]\ttrain-auc:0.939966\ttrain-ams@0.15:5.46013\n",
      "[57]\ttrain-auc:0.940123\ttrain-ams@0.15:5.48477\n",
      "[58]\ttrain-auc:0.94029\ttrain-ams@0.15:5.50458\n",
      "[59]\ttrain-auc:0.940434\ttrain-ams@0.15:5.51442\n",
      "[60]\ttrain-auc:0.940661\ttrain-ams@0.15:5.52921\n",
      "[61]\ttrain-auc:0.940794\ttrain-ams@0.15:5.53396\n",
      "[62]\ttrain-auc:0.940968\ttrain-ams@0.15:5.54784\n",
      "[63]\ttrain-auc:0.941121\ttrain-ams@0.15:5.56274\n",
      "[64]\ttrain-auc:0.941214\ttrain-ams@0.15:5.56111\n",
      "[65]\ttrain-auc:0.941395\ttrain-ams@0.15:5.59597\n",
      "[66]\ttrain-auc:0.941601\ttrain-ams@0.15:5.62109\n",
      "[67]\ttrain-auc:0.941708\ttrain-ams@0.15:5.61596\n",
      "[68]\ttrain-auc:0.941897\ttrain-ams@0.15:5.63869\n",
      "[69]\ttrain-auc:0.941995\ttrain-ams@0.15:5.63148\n",
      "[70]\ttrain-auc:0.942161\ttrain-ams@0.15:5.63832\n",
      "[71]\ttrain-auc:0.942268\ttrain-ams@0.15:5.65406\n",
      "[72]\ttrain-auc:0.942431\ttrain-ams@0.15:5.67709\n",
      "[73]\ttrain-auc:0.942546\ttrain-ams@0.15:5.67806\n",
      "[74]\ttrain-auc:0.942675\ttrain-ams@0.15:5.69098\n",
      "[75]\ttrain-auc:0.942762\ttrain-ams@0.15:5.70687\n",
      "[76]\ttrain-auc:0.94289\ttrain-ams@0.15:5.70974\n",
      "[77]\ttrain-auc:0.943008\ttrain-ams@0.15:5.70625\n",
      "[78]\ttrain-auc:0.943079\ttrain-ams@0.15:5.71726\n",
      "[79]\ttrain-auc:0.943189\ttrain-ams@0.15:5.72382\n",
      "[80]\ttrain-auc:0.943346\ttrain-ams@0.15:5.7159\n",
      "[81]\ttrain-auc:0.94344\ttrain-ams@0.15:5.73729\n",
      "[82]\ttrain-auc:0.943517\ttrain-ams@0.15:5.74225\n",
      "[83]\ttrain-auc:0.943664\ttrain-ams@0.15:5.75474\n",
      "[84]\ttrain-auc:0.943768\ttrain-ams@0.15:5.76665\n",
      "[85]\ttrain-auc:0.943839\ttrain-ams@0.15:5.79082\n",
      "[86]\ttrain-auc:0.943905\ttrain-ams@0.15:5.79195\n",
      "[87]\ttrain-auc:0.944008\ttrain-ams@0.15:5.79727\n",
      "[88]\ttrain-auc:0.944115\ttrain-ams@0.15:5.80257\n",
      "[89]\ttrain-auc:0.94419\ttrain-ams@0.15:5.80373\n",
      "[90]\ttrain-auc:0.944317\ttrain-ams@0.15:5.8095\n",
      "[91]\ttrain-auc:0.94441\ttrain-ams@0.15:5.82166\n",
      "[92]\ttrain-auc:0.94448\ttrain-ams@0.15:5.81602\n",
      "[93]\ttrain-auc:0.944652\ttrain-ams@0.15:5.83914\n",
      "[94]\ttrain-auc:0.944773\ttrain-ams@0.15:5.85633\n",
      "[95]\ttrain-auc:0.944897\ttrain-ams@0.15:5.85874\n",
      "[96]\ttrain-auc:0.945028\ttrain-ams@0.15:5.86489\n",
      "[97]\ttrain-auc:0.945208\ttrain-ams@0.15:5.88279\n",
      "[98]\ttrain-auc:0.945322\ttrain-ams@0.15:5.88634\n",
      "[99]\ttrain-auc:0.945467\ttrain-ams@0.15:5.8927\n",
      "[100]\ttrain-auc:0.945529\ttrain-ams@0.15:5.90102\n",
      "[101]\ttrain-auc:0.945587\ttrain-ams@0.15:5.90017\n",
      "[102]\ttrain-auc:0.945634\ttrain-ams@0.15:5.90159\n",
      "[103]\ttrain-auc:0.94571\ttrain-ams@0.15:5.90521\n",
      "[104]\ttrain-auc:0.945849\ttrain-ams@0.15:5.91721\n",
      "[105]\ttrain-auc:0.945928\ttrain-ams@0.15:5.94371\n",
      "[106]\ttrain-auc:0.94602\ttrain-ams@0.15:5.92908\n",
      "[107]\ttrain-auc:0.946089\ttrain-ams@0.15:5.93255\n",
      "[108]\ttrain-auc:0.94617\ttrain-ams@0.15:5.93923\n",
      "[109]\ttrain-auc:0.94632\ttrain-ams@0.15:5.96179\n",
      "[110]\ttrain-auc:0.946404\ttrain-ams@0.15:5.96363\n",
      "[111]\ttrain-auc:0.946512\ttrain-ams@0.15:5.97068\n",
      "[112]\ttrain-auc:0.946592\ttrain-ams@0.15:5.97663\n",
      "[113]\ttrain-auc:0.946646\ttrain-ams@0.15:5.97627\n",
      "[114]\ttrain-auc:0.946798\ttrain-ams@0.15:5.99764\n",
      "[115]\ttrain-auc:0.946853\ttrain-ams@0.15:6.00183\n",
      "[116]\ttrain-auc:0.946935\ttrain-ams@0.15:6.00257\n",
      "[117]\ttrain-auc:0.946989\ttrain-ams@0.15:6.00539\n",
      "[118]\ttrain-auc:0.947092\ttrain-ams@0.15:6.00348\n",
      "[119]\ttrain-auc:0.947227\ttrain-ams@0.15:6.01156\n",
      "finish training\n"
     ]
    }
   ],
   "source": [
    "# XGBoost test code below\n",
    "test_size = 550000\n",
    "\n",
    "# path to where the data lies\n",
    "dpath = '../../data/'\n",
    "\n",
    "# load in training data, directly use numpy\n",
    "dtrain = np.loadtxt( dpath+'/training.csv', delimiter=',', skiprows=1, converters={32: lambda x:int(x=='s'.encode('utf-8')) } )\n",
    "print ('finish loading from csv ')\n",
    "\n",
    "label  = dtrain[0:225000,32]\n",
    "data   = dtrain[0:225000,1:31]\n",
    "# rescale weight to make it same as test set\n",
    "weight = dtrain[0:225000,31] * float(test_size) / len(label)\n",
    "\n",
    "sum_wpos = sum( weight[i] for i in range(len(label)) if label[i] == 1.0  )\n",
    "sum_wneg = sum( weight[i] for i in range(len(label)) if label[i] == 0.0  )\n",
    "\n",
    "# print weight statistics\n",
    "print ('weight statistics: wpos=%g, wneg=%g, ratio=%g' % ( sum_wpos, sum_wneg, sum_wneg/sum_wpos ))\n",
    "\n",
    "# construct xgboost.DMatrix from numpy array, treat -999.0 as missing value\n",
    "xgmat = xgb.DMatrix( data, label=label, missing = -999.0, weight=weight )\n",
    "\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use logistic regression loss, use raw prediction before logistic transformation\n",
    "# since we only need the rank\n",
    "param['objective'] = 'binary:logitraw'\n",
    "# scale weight of positive examples\n",
    "param['scale_pos_weight'] = sum_wneg/sum_wpos\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['eval_metric'] = 'auc'\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 16\n",
    "\n",
    "# you can directly throw param in, though we want to watch multiple metrics here\n",
    "plst = list(param.items())+[('eval_metric', 'ams@0.15')]\n",
    "\n",
    "watchlist = [ (xgmat,'train') ]\n",
    "# boost 120 tres\n",
    "num_round = 120\n",
    "print ('loading data end, start to boost trees')\n",
    "bst = xgb.train( plst, xgmat, num_round, watchlist );\n",
    "# save out model\n",
    "bst.save_model('higgs.model')\n",
    "\n",
    "print ('finish training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct test data\n",
    "tLabel  = dtrain[225001:250000,32]\n",
    "tData   = dtrain[225001:250000,1:31]\n",
    "# rescale weight to make it same as test set\n",
    "tWeight = dtrain[225001:250000,31] * float(test_size) / len(label)\n",
    "\n",
    "# construct xgboost.DMatrix from numpy array, treat -999.0 as missing value\n",
    "xgmat = xgb.DMatrix( tData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict classes\n",
    "ypred = bst.predict(xgmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make top 15% positive\n",
    "idx = dtrain[225001:250000,0]\n",
    "threshold_ratio = 0.15\n",
    "res  = [ ( int(idx[i]), ypred[i] ) for i in range(len(ypred)) ]\n",
    "\n",
    "rorder = {}\n",
    "for k, v in sorted( res, key = lambda x:-x[1] ):\n",
    "    rorder[ k ] = len(rorder) + 1\n",
    "ntop = int( threshold_ratio * len(rorder ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24999"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24999"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "myPred = []\n",
    "nhit = 0\n",
    "for k, v in res:\n",
    "    # if rorder[k] <= ntop:\n",
    "    if v > 0:\n",
    "        lb = 's'\n",
    "        nhit += 1\n",
    "    else:\n",
    "        lb = 'b'\n",
    "    # change output rank order to follow Kaggle convention\n",
    "    myPred.append(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute AMS\n",
    "def ams(s, b):\n",
    "    from math import sqrt,log\n",
    "    if b==0:\n",
    "        return 0\n",
    "\n",
    "    return sqrt(2*((s+b+10)*log(1+float(s)/(b+10))-s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute all measures\n",
    "def validate(predicted, real, weights):\n",
    "    sumsig = 0.\n",
    "    sumbkg = 0.\n",
    "    tp = 0.\n",
    "    tn = 0.\n",
    "    fp = 0.\n",
    "    fn = 0.\n",
    "    precision = 0.\n",
    "    recall = 0.\n",
    "    acc = 0.\n",
    "    \n",
    "    if (predicted.shape[0] != real.shape[0]):\n",
    "        raise Exception\n",
    "    \n",
    "    for i in range(predicted.shape[0]):\n",
    "        if predicted[i] == \"s\":\n",
    "            if real[i] == \"s\":\n",
    "                sumsig += weights[i]\n",
    "                tp += 1\n",
    "            else:\n",
    "                sumbkg += weights[i]\n",
    "                fp += 1\n",
    "        else:\n",
    "            if real[i] == \"s\":\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    \n",
    "    print(tp, fp, fn, tn)\n",
    "    \n",
    "    # calculate scores\n",
    "    amsscore = ams(sumsig * 10, sumbkg * 10)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "    f1score = (2 * precision * recall)/(precision + recall)\n",
    "\n",
    "    printScores(tp, tn, fp, fn, precision, recall, acc, f1score, amsscore)\n",
    "    \n",
    "    return amsscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printScores(tp, tn, fp, fn, precision, recall, acc, f1score, amsscore):\n",
    "    all = tp + tn + fp + fn\n",
    "    print(\"TP: \", tp/all)\n",
    "    print(\"TN: \", tn/all)\n",
    "    print(\"FP: \", fp/all)\n",
    "    print(\"FN: \", fn/all)\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"Acc: \", acc)\n",
    "    print(\"F1: \", f1score)\n",
    "    print(\"AMS: \", amsscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6939.0 3495.0 1670.0 12895.0\n",
      "TP:  0.27757110284411374\n",
      "TN:  0.515820632825313\n",
      "FP:  0.13980559222368893\n",
      "FN:  0.06680267210688427\n",
      "Precision:  0.6650373778033353\n",
      "Recall:  0.8060169589963991\n",
      "Acc:  0.7933917356694268\n",
      "F1:  0.7287717271438323\n",
      "AMS:  3.7349642532420426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.7349642532420426"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(np.array(myPred), np.array(pd.Series(tLabel).map({1: 's', 0: 'b'})), np.array(tWeight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
