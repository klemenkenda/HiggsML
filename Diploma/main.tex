% !TeX spellcheck = sl_SI
\documentclass[11pt,a4paper,openany]{book}
\usepackage[slovene]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath, fullpage}
\usepackage{epsfig}
\usepackage{setspace}
\usepackage{color}
\usepackage{amsfonts}
\usepackage{url}
\usepackage{fancyhdr}
\usepackage{parskip}
% \usepackage[dvips]{graphicx}
\usepackage[titletoc]{appendix}
\usepackage[dvips]{xy}
\usepackage[font=small,format=plain,labelfont=bf,up,textfont=it,up]{caption}
\onehalfspacing

\begin{document}
\input{macros}

% -----------------------------------------------------------------------------
% UVODNESTRANI
% -----------------------------------------------------------------------------
\input{intropages}







% -----------------------------------------------------------------------------
% POVZETEK
% -----------------------------------------------------------------------------
\chapter*{Povzetek}
\addcontentsline{toc}{chapter}{Povzetek}

Plan dela:
\begin{itemize}
	\item Osnovno razumevanje fizikalnega dela + opis
	\item Exploratory analysis + opis podatkov
	\item Usposobitev baseline (predlaganih) metod
		\begin{itemize}
			\item Simple Window
			\item Naive Bayes
			\item XGBoost
		\end{itemize}
	\item Delo na ostalih metodah + opis metod
		\begin{itemize}
			\item Logistic regression
			\item Perceptron
			\item NN
			\item SVM
		\end{itemize}
	\item Izboljšava metod
		\begin{itemize}
			\item Na podlagi logistične regresije
			\item Na podlagi SVM
		\end{itemize}
\end{itemize} 

\vspace{1.3cm}
\noindent
{\large \bf Ključne besede:}

\vspace{0.5cm}
\noindent test, test, test


Abstract. Key words.







% -----------------------------------------------------------------------------
% UVOD
% -----------------------------------------------------------------------------
\chapter*{Uvod}
\addcontentsline{toc}{chapter}{Uvod}

Eksperimenta ATLAS in CMS sta leta 2012 objavila odkritje Higgsovega bozona\cite{Aad20121,Chatrchyan201230}. Odkritju je leta 2013 sledila Nobelova nagrada za fiziko, ki sta jo prejela François Englert in Peter Higgs. Obstoj delca, katerega vloga naj bi bila, da daje maso ostalim elementarnim delcem, je bil predviden pred skoraj 50 leti. Eksperimenti so potekali (in še vedno potekajo) na Velikem hadronskem trkalniku (Large Hadron Collider - LHC) v CERN-u (Evropski organizaciji za jedrske raziskave) v Ženevi\cite{ChallengeDoc}.

Higgsov bozon lahko razpade skozi različne procese, ki jim v fiziki osnovnih delcev pravimo kanali. Pri tem nastanejo novi delci. Higgsov bozon so najprej opazili v treh različnih razpadnih kanalih, v katerih vedno nastanejo pari bozonov. V naslednjem koraku je bilo potrebno najti dokaze o razpadu Higgsovega bozona v fermionske pare, predvsem v $\tau$ leptone in $b$ kvarke. Prvi dokazi o $H \rightarrow \tau^+\tau^-$ so bili predstavljeni v \cite{atlas2013}. \comment{Ali so rezultati $H \rightarrow \tau^+\tau^-$ že kje? Se to kaj navede?}

Pri analizi eksperimentalnih podatkov je potrebno določiti relevantno območje faznega prostora izmerjenih značilk, v katerem je velika verjetnost, da smo naleteli na dogodke, ki nas zanimajo (v našem primeru na razpad $H \rightarrow \tau^+\tau^-$). V preteklosti so ta področja določali eksperti \textit{ročno}\cite{Adam-Bourdarios14}. Napredne klasifikacijske metode, ki temeljijo na strojnem učenju, pa se danes rutinirano uporabljajo za reševanje tega in podobnih problemov\cite{atlas2013}.

Področje dela tesno povezuje fiziko z računalništvo, natančneje - s strojnim učenjem. 

Namen diplomskega dela je predvsem seznaniti se z uporabo metod strojnega učenja pri ločevanju signala in ozadja pri razpadu $H \rightarrow \tau^+\tau^-$, preveriti in ovrednotiti različne klasifikacijske metode na podatkih simulatorja ATLAS in preveriti proces optimizacije teh metod, ki izhaja iz podatkov (in ne nujno domenskega znanja). Sekundarni cilj je razvoj lastne klasifikacijske metode, ki bo temeljila na metodi podpornih vektorjev (SVM).

Še enkrat velja izpostaviti, da se diplomsko delo nanaša predvsem na uporabo metod strojnega učenja pri analizi zahtevnih in analitično neobvladljivih problemov, in ne na fiziko osnovnih delcev in razlago standardnega modela (SM).

\comment{Če zmagovalna metoda na lepih podatkih doseže AMS 3,7, kako lahko na podlagi teh}
\comment{rezultatov pridemo do $\sigma = 5$??}

\section*{Izziv HiggsML}
\comment{Opis challenge-a.}
\comment{Globoko fizikalno razumevanje načeloma v tem izzivu ni pripomoglo k signifikantnemu izboljšanju}
\comment{klasifikacijskih modelov. Osnovne izpeljane vrednosti so zadoščale!}
\comment{Vir: https://www.kaggle.com/c/higgs-boson/forums/t/10350/how-physicists-fared}


\section*{Terminologija}
\addcontentsline{toc}{section}{Terminologija}

Ker je področje strojnega učenja in umetne inteligence v slovenskem prostoru majhno in ker se slovenska terminologija na tem področju še redkeje uporablja in je zato tudi strokovno podkovanemu bralcu manj znana, na tem mestu prilagamo kratek slovarček strokovnih terminov s področja strojnega učenja. Vsi prevodi temeljijo na \textit{Računalniškem slovarčku}, ki ga vzdržuje Odsek za inteligentne sistem na Inštitutu "Jožef Stefan"\footnote{\url{http://dis-slovarcek.ijs.si}}.

\input{slovar}

% -----------------------------------------------------------------------------
% POGLAVJE: Fizikalne osnove
% -----------------------------------------------------------------------------
\chapter{Fizikalne osnove}

\comment{Osnovni članek: \cite{AadScience2012}.}


\section{Razpad $H \rightarrow \tau^+\tau^-$}

\cite{Baldi2014} \cite{atlas2013}


\section{ATLAS detektor}
\cite{AadScience2012}


\section{Posebna teorija relativnosti}
Podpoglavje opisuje nekaj osnovnih enačb iz posebne teorije relativnosti in sledi predvsem izpeljavi novih značilk iz surovih podatkov. Izpeljane značilke si je moč ogledati v podpoglavju \ref{opis-podatkov}.

\subsection{Gibalna količina, masa in energija}
Fundamentalna enačba posebne teorije relativnostni
\begin{equation}
	E^2 = p^2c^2 + m^2c^4,
	\label{stirimoment}
\end{equation}
\comment{Strnad 3/39 (9)}
kjer je $E$ energija delca, $p$ njegova gibalna količina, $m$ lastna masa (masa v mirovanju) in $c$ hitrost svetlobe v praznem prostoru. V primeru, ko delec miruje (in ima s tem gibalno količino enako $0$), se enačba poenostavi v znano $E = mc^2$.

\comment{Relevantno za izpeljavo značilk! Navedba/izpeljava enačb za izpeljane vrednosti ... \cite{Adam-Bourdarios14}}
\comment{Mogoče smiselno citirati tudi Strnada 3?}

% -----------------------------------------------------------------------------
% POGLAVJE: Opredelitev problema
% -----------------------------------------------------------------------------
\chapter{Opredelitev problema}

Problem, s katerim sem se spopadel v diplomskem delu, sledi formulaciji na odprtem tekmovanju \textit{The Higgs Boson Machine Learning Challenge (HiggsML)}\footnote{ \url{http://www.kaggle.com/c/higgs-boson}}, ki temelji na rezultatih kolaboracije ATLAS\cite{Adam-Bourdarios14}. 


\section{Formalna opredelitev problema}

Naj ${\cal D} = \left\{({\mathbf x}_1, y_1, w_1, \dots, ({\mathbf x}_n, y_n, w_n) \right\}$ predstavlja učno podatkovno množico, kjer je $\mathbf{x}_i \in \mathbb{R}^d$ $d$-dimenzionalni vektor značilk, $y_i \in \{\text{b, s}\}$ je oznaka, $w_i \in \mathbb{R}^+$ pa je nenegativna utež. Naj bosta ${\cal S} = \{i : y_i = \text{s}\}$ in ${\cal B} = \{i : y_i = \text{b}$ množici indeksov dogodkov, ki predstavljajo signal in ozadje, $n_\text{s} = |{\cal S}|$ in $n_\text{b} = |{\cal B}|$ pa naj označujeta števili simuliranih dogodkov, ki predstavljata signal in ozadje.

Podatki, na katerih se učimo, so simulirani (glej poglavje \ref{analiza-podatkov}) in se razlikujejo od izmerjenih. Razmerje $n_\text{s} / n_\text{b}$ v podatkih tako ne odraža dejanskega razmerja dogodkov $P(y = s) / P(y = b)$. Glede ne nizko verjetnost, da pri nekem naravnem dogodku gre za signal \cite{Adam-Bourdarios14}, je tako učna podatkovna množica precej bolj uravnotežena in omogoča metodam, da se lahko naučijo razlikovati med dogodki, ki predstavljajo ozadje in tistimi, ki predstavljajo signal.

Podatek, ki ga da simulacija, je tudi utež $w_i$, ki je mera za pomembnost nekega simuliranega dogodka. Ker je optimizacijska funkcija (\ref{en:ams}) odvisna od \textit{nenormalizirane vsote} uteži in ker želimo, da je naš sistem invarianten na števili simuliranih dogodkov $n_s$ in $n_b$, moramo vsoto vsake podatkovne množice (učne, validacijske ...) za vsak razred (signal ali ozadje) fiksirano:
\begin{equation}
\sum_{i \in \cal{S}}{w_i} = N_s
\qquad\text{in}\qquad
\sum_{i \in \cal{B}}{w_i} = N_b
\end{equation}
Normalizacijski konstanti $N_s$ in $N_b$ imata fizikalni pomen in predstavljata \textit{pričakovano število} dogodkov ki predstavljajo signal in ozadje, med intervalom zajema podatkov (v našem primeru leta 2012). Individualne uteži so proporcionalne pogojnim gostotam, deljenimi z instrumentalnimi gostotami, uporabljenimi na simulatorju.

\begin{equation}
	w_i = \left\{\begin{array}{r}
		p_s(\textbf{x}_i)/q_s(x_i),\qquad \text{if}\;y_i = s \\
		p_b(\textbf{x}_i)/q_b(x_i),\qquad \text{if}\;y_i = b 
	\end{array}
	\right.,
\end{equation}
kjer sta
\begin{equation*}
p_s(\textbf{x}_i) = p(\textbf{x}_i|y = s) \qquad in \qquad p_b(\textbf{x}_i) = p(\textbf{x}_i|y = b)
\end{equation*}
pogojni gostoti signala in ozadja ter $q_s(\textbf{x}_i)$ in $q_b(\textbf{x}_i)$ instrumentalni gostoti.

Naj bo $g : \mathbb{R}^d \rightarrow \{b, s\}$ poljubna klasifikacijska funkcija. Naj bo izbrano področje ${\cal G} = \{\textbf{x} : g(\textbf{x}) = s\}$ množca točk, klasificirana kod signal, in naj $\hat{\cal G}$ označuje množico indeksov točk, ki jih $g$ izbere (klasificira kot signal).
\begin{equation*}
\hat{\cal G} = \{ i : \textbf{x}_i \in {\cal G}\} = \{ i : g(\textbf{x}_i) = s \}.
\end{equation*}


\section{AMS metrika}

\begin{equation}
\text{AMS} = \sqrt{2 \left( ( s + b + b_{reg} ) \ln \left( 1 +  \frac{s}{b + b_{reg}} \right) - s \right) }
\label{en:ams}
\end{equation}

% -----------------------------------------------------------------------------
% POGLAVJE: Metode strojnega učenja
% -----------------------------------------------------------------------------
\chapter{Strojno učenje}

\cite{Mitchell1997}, \cite{Witten2005}.

\section{Raziskovalna analiza podatkov}
Raziskovalna analiza podatkov predstavlja enega od pristopov k začetni analizi množice podatkov predvsem s pomočjo vizualnih metod. Opisi v pričujočem poglavju sledijo \cite{hand2001}.

\subsection{Osnovni pregled značilk}
5-figure description
manjkajoče vrednosti
histogrami

\subsection{Korelacijska matrika značilnosti}



\comment{Hierarhični clustering}.

\subsection{Scatter plots}

\subsection{Analza glavnih komponent}
Analiza glavnih komponent (\textit{Principal component analysis}, PCA) je definirana kot ortogonalna linearna transformacija, ki transformira nabor podatkov v nov koordinatni sistem, in sicer tako, da komponenta z največjo varianco neke projekcije podatkov leži na prvi koordinati, druga največja na drugem mestu in tako naprej.




\section{Metode za nadzorovano učenje}

\section{Pregled klasifikacijskih metod}

V tipičnem klasifikacijskem problemu imamo množico vektorjev v prostoru $x_i \in \mathbb{R}^d$ (vektor značilk) in pripadajočih oznak $l_i \in {1, 2, 3, \ldots, N}$, kjer $N$ označuje število različnih razredov. Oznaka $l_i$ nam pove, v kateri razred spada vektor $x_i$. Cilj klasifikacijskega problema je predvideti oznake neznanih vektorjev, in sicer tako, da bo pri tem napaka najmanjša.

Za binarne klasifikacijske probleme velja $N = 2$. V takih primerih obstajata 2 razreda: pozitivni in negativni. S takšnim problemom se srečujemo tudi v tem diplomskem delu.

\subsection{Logistična regresija}

\subsection{Naivni Bayesov klasifikator}

\subsection{Metoda podpornih vektorjev}

Denimo, da imamo binarni klasifikacijski problem in da sta razreda točk v našem prostoru linearno separabilna. V večini takih primerov obstaja neskončno mnogo različnih hiperravnin, ki ločujejo med sabo oba razreda (glej sliko \ref{svmseparable}).

\begin{figure}[ht]
	\includegraphics[width=5.2cm]{methods/svm/svm_axes_1.pdf}
	\includegraphics[width=5.2cm]{methods/svm/svm_axes_2.pdf}
	\includegraphics[width=5.2cm]{methods/svm/svm_axes_3.pdf}	
	
	\caption{Veliko različnih rešitev za hiperravnino, ki ločuje razreda primerkov.}
	\label{svmseparable}
\end{figure}

Metoda podpornih vektorjev (\textit{angl. Support Vector Machine} oz. SVM) se imenuje tudi klasifikator maksimalnega razmika. Prej opisani problem binarne klasifikacije s tem dobi enolično rešitev. Primer klasifikatorja z maksimalnim razmikom je ilustriran na sliki \ref{svmmaxclass}.

\comment{Pripravi sliko!}

\comment{Vključi komentar o več dimenzijah in uporabo kernelov.}

Hiperravnino, ki ločuje različna razreda primerkov označimo s $H$. Enačbo ravnine lahko zapišemo kot
\begin{equation}
  w^T x + b = 0,
\end{equation}
kjer je $w$ normalni vektor (v našem kontekstu ga bomo imenovali \textit{vektor uteži}), $b$ pa odmik ravnine v izhodišču.

Za enolično reprezentacijo hiperravnine je potrebno normalizirati faktorja $w$ in $b$. Taki reprezentaciji pravimo tudi kanonična reprezentancija.

\comment{Pride nekje do AMS 2,7.}
\comment{https://www.kaggle.com/c/higgs-boson/forums/t/10165/has-anyone-tried-the-support-vector-machine-for-this-problem}
\comment{Tu se splača igrat s kerneli.}

\subsection{Nevronske mreže}
\comment{Deep NN - zmagovalna metoda. Ansambli.}

\subsubsection{Perceptron}

\subsubsection{Umetne nevronske mreže - aNN}

\subsubsection{Globoke nevronske mreže}

\subsubsection{Ansambli}

\subsection{Pospešena odločitvena drevesa}
\comment{TMVA boosted trees? XGBoost - metoda, ki je manj potratna.}
\comment{http://higgsml.lal.in2p3.fr/software/hep-tmva-kit/}
\comment{http://higgsml.lal.in2p3.fr/software/multiboost/}
\comment{https://github.com/dmlc/xgboost}


% -----------------------------------------------------------------------------
% POGLAVJE: Podatki
% -----------------------------------------------------------------------------
\chapter{Podatki}
\label{analiza-podatkov}
Podatki, ki sem jih uporabil v diplomskem delu, so bili uporabljeni za izvedbo \textit{HiggsML Challenge}. Podatki predstavljajo dogodke, ki so bili simulirani na uradnem simulatorju polnega detektorja kolaboracija ATLAS\cite{Adam-Bourdarios14}. Podatki iz simulatorja imajo lastnosti, ki posnemajo statistične lastnosti dejanskih dogodkov - tako signala, kakor tudi ozadja.

Vzorec signala zajema dogodke, v katerih naj bi nastal Higgsov bozon (katrega masa je bila nastavljena na $m_H = 125\,\text{GeV}$). Vzorec, ki predstavlja ozadje, vsebuje dogodke, ki odražajo druge znane procese, ki lahko proizvajajo dogodke z vsaj enim elektronom ali mionom in hadronskim tau, ki posnemajo signal.

V simuliranih podatkov so predstavljeni samo trije procesi ozadja. Prvi prihaja od razpada $Z \rightarrow \tau^+\tau^-$ (masa z bozona je $m_Z = 91.2\,\text{GeV}$). Ta razpad proizvaja dogodke s topologijo, ki je zelo podobna tisti pri razpadu Higgsovega bozona. Druga množica dogodkov vsebuje par $t$ kvarkov, ki imata lahko med svojimi razpadnimi produkti lepton ali hadronski tau. Tretja množica vsebuje razpad $W$ bozona, kjer lahko nastaneta en elektron ali mion in hadronski tau. 

\section{Opis podatkov}

V učni podatkovni množici je na voljo 250.000 dogodkov, od teh jih je 85.667 predstavljalo signal, 164.333 pa ozadje. Vsak dogodek je predstavljen z $d = 30$ značilkami, ki so dodatno opisane v \ref{sec:opis-znacilk}, in 3 metapodatki: oznako razreda ($s$ - signal ali $b$ - ozadje), utežjo $w_i$ in zaporedno številko dogodka. Raziskovalna analiza podatkov je predstavljena v \ref{sec:raziskovalna-analiza}.

Potrjevalna podatkovna množica vsebuje 100.000 dogodkov, ki pa niso opremljeni z oznako razreda ali utežjo $w_i$. 

\subsection{Opis značilk}
\label{sec:opis-znacilk}
Podatki zajemajo $d = 30$ značilk, katerih opis je povzet po \cite{Adam-Bourdarios14}. Stolpci s predpono PRI (ki označuje \textit{PRImitives}) predstavlja \textit{surove} podatke o trkih, kot jih izmeri detektor. Stolpci s predpono DER (ki označuje \textit{DERived}) predstavljajo vrednosti, izpeljane iz primitivnih lastnosti. Količine so določili sodelavci kolaboracije ATLAS z namenom, da bi pomagale definirati relevantna področja faznega prostora za klasifikacijske metode.

Stolpci brez predpone imajo posebno vlogo in se ne uporabljajo kot značilke:

\begin{changemargin}{0.5cm}{0.0cm} 
\begin{description}
	\item [EventId] 	Zaporedna številka dogodka.
	\item [Weight]  	Utež dogodka $w_i$, kakor je opisana v podpoglavju \ref{utez}.
	\item [Label] 		Oznaka dogodka (niz) $y_i \in \{\text{s}, \text{b}\}$ (s za signal, b za ozadje).	
\end{description}
\end{changemargin}

Stolpci s predpono \textbf{PRI} označujejo \textit{surove} podatke, ki jih detektor izmeri pri trku:
\begin{changemargin}{0.5cm}{0.0cm} 
\begin{description}
	\item[PRI\_tau\_pt] Prečni (transverse???) moment $\sqrt{p_x^2 + p_y^2}$ hadronskega tau.
	\item[PRI\_tau\_eta] Psevdorapidnost $\eta$ hadronskega tau.
	\item[PRI\_tau\_phi] Azimutalni kot $\phi$ hadronskega tau.
	
	\item[PRI\_lep\_pt] Prečni moment $\sqrt{p_x^2 + p_y^2}$ leptona (elektrona ali miona).
	\item[PRI\_lep\_eta] Psevdorapidnost $\eta$ leptona.
	\item[PRI\_lep\_phi] Azimutalni kot $\phi$ leptona.
	
	\item[PRI\_met] Manjkajoča prečna energija $\vec{E}_T^{\text{miss}}$.
	\item[PRI\_met\_phi] Azimutalni kot $\phi$ manjkajoče prečne energije.
	
	\item[PRI\_met\_sumet] Celotna prečna energija v detektorju.
	
	\item[PRI\_jet\_num] Število vseh žarkov ($\in {1, 2, 3}$), vednosti, večje od $3$ so bile zamenjane s 3
	
	\item[PRI\_jet\_leading\_pt] Prečni moment $\sqrt{p_x^2 + p_y^2}$ glavnega žarka, t. j. žarka z največjo prečno energijo (vrednost ni definirana pri vrednosti značilke $\textbf{PRI\_jet\_num} = 0$).
	\item[PRI\_jet\_leading\_eta] Psevdorapidnost $\eta$ glavnega žarka (vrednost ni definirana pri vrednosti značilke $\textbf{PRI\_jet\_num} = 0$).
	\item[PRI\_jet\_leading\_phi] Azimutalni kot $\phi$ glavnega žarka (vrednost ni definirana pri vrednosti značilke $\textbf{PRI\_jet\_num} = 0$).
	
	\item[PRI\_jet\_subleading\_pt] Prečni moment $\sqrt{p_x^2 + p_y^2}$ prvega pomožnega žarka, t. j. žarka z drugo največjo prečno energijo (vrednost ni definirana pri vrednosti značilke $\textbf{PRI\_jet\_num} \le 0$).
	\item[PRI\_jet\_subleading\_eta] Psevdorapidnost $\eta$ prvega pomožnega žarka, t. j. žarka z drugo največjo (vrednost ni definirana pri vrednosti značilke $\textbf{PRI\_jet\_num} \le 0$).
	\item[PRI\_jet\_subleading\_phi] Azimutalni kot $\phi$ prvega pomožnega žarka (vrednost ni definirana pri vrednosti značilke $\textbf{PRI\_jet\_num} \le 0$).
	
	\item[PRI\_jet\_all\_pt] Skalarna vsota prečnih momentov vseh žarkov pri dogodkih.
\end{description}
\end{changemargin}

Stolpci s predpono \textbf{DER} označujejo iz surovih podatkov izpeljane količine:
\begin{changemargin}{0.5cm}{0.0cm} 
\begin{description}
	\item[DER\_mass\_MMC] Ocenjena masa kandidata za Higgsov bozon $m_H$, pridobljena s pomočjo (\comment{MC?}) verjetnostne integracije po faznem prostoru (vrednost ni definirana v primeru, da topologija dogodka preveč odstopa od pričakovane)
	\item[DER\_mass\_transverse\_met\_lep] Prečna masa med manjkajočo prečno energijo in leptonom.
	\item[DER\_mass\_vis] Invarianta masa hadronskega $\tau$ in leptona.
	\item[DER\_pt\_h] Modulus ... \comment{uf, preveri!}
	\item[DER\_deltaeta\_jet\_jet] Absolutna vrednost psevdorapidnostne separacije med obema žarkoma (vrednost ni definirana v primeru $PRI\_jet\_num \le 1$).
	\item[DER\_mass\_jet\_jet] Invariantna masa obeh žarkov (vrednost ni definirana pri $PRI\_jet\_num \le 1$).
	\item[DER\_prodeta\_jet\_jest] Produkt psevdorapidnosti obeh žarkov (vrednost ni definirana pri $PRI\_jet\_num \le 1$).
	
\end{description}
\end{changemargin}

\comment{Vse izpeljane vrednosti so definirane v dodatku! Referenciranje na ustrezne enačbe!}

\section{Rezultati raziskovalne analiza podatkov}
\label{sec:raziskovalna-analiza}

\subsection{Manjkajoči podatki}

, tabela \ref{manjkajoče} pa predstavlja dogodke z manjkajočimi vrednostmi določenih značilk.

\begin{table}[ht]
	\centering
	\begin{tabular}{ccc}
		\hline
		{} & \textbf{signal} & \textbf{ozadje} \\
		\hline
		brez curkov & $81002\;(29,6\%)$ & $239967\;(45,3\%)$ \\
		1 curek & $88189\;(32,3\%)$ & $159071\;(30,2\%)$ \\
		vsi curki & $169191\;(61,9\%)$ & $398139\;(75,5\%)$ \\
		\hline
		Higgsova masa & $9011\;(3,3\%)$ & $114925\;(21,8\%)$
		
	\end{tabular}
	\caption{Manjkajoče značilke, število dogodkov in odstotek v razred.}
	\label{manjkajoče}
\end{table}


\comment{Večina gre v dodatek.}

	
% -----------------------------------------------------------------------------
% POGLAVJE: Rezultati osnovnih metod
% -----------------------------------------------------------------------------
\chapter{Rezultati osnovnih metod}
	
\subsection{Preprosto okno}
\comment{http://higgsml.lal.in2p3.fr/software/simplest-python-kit/}
	
% -----------------------------------------------------------------------------
% POGLAVJE: Izboljševanje metod in razvoj lastne metode
% -----------------------------------------------------------------------------
\chapter{Izboljševanje metod in razvoj lastne metode}
\label{raziskovalna_analiza}

Vse implementacije sem naredil v programskem jeziku Python z uporabo paketa \texttt{scikit-learn}\cite{scikit-learn}. Za pospešena odločitvena drevesa sem uporabil nagrajeni paket XGBoost\cite{chen2014}.

\section{Izbira značilk}
	
\section{Generiranje novih značilk}
\comment{Poglavje 6 - ali so te količine dovolj?} \cite{Adam-Bourdarios14}

\section{Fine tuning}

\section{Razvoj metode na podlagi SVM}

\comment{Nekaj idej:}
\comment{Problem je v nelinearnosti. Zato je treba nelinearnost pripeljat v SVM.}
\comment{To naredimo s pomočjo različnih kernelov, in generiranja novih featurejev.}
\comment{Feature je lahko na enem atributu - logaritem, ekspoment, kakšna druga podobna naravna funkcija - tudi poljubna.}
\comment{Ali pa na dveh. Več kod dveh se skoraj ne splača uporabljat. Vsote, zmnožki, diference, $e^y$.}
\comment{En zanimiv feature se da generirat s pomočjo KMeans clusteringa - kar ID clustra.}
\comment{SVM z veliko featureji načeloma ne bi smel biti nič slabši kot deep NN.}
\comment{Problem je samo, da se mu te feature-je porine ...}
\comment{SVM zna najti iglo v kopici sena ... Torej - če se bo našel en dober feature, ga bo sVM našel.}
\comment{Prednost SVM je še v tem, da ni black-box, da se da razumeti stvar.}

\section{Rezultati}




% -----------------------------------------------------------------------------
% POGLAVJE: Zaključek
% -----------------------------------------------------------------------------
\chapter*{Zaključek}
\addcontentsline{toc}{chapter}{Zaključek}

% -----------------------------------------------------------------------------
% ZAKLJUČNE STRANI
% -----------------------------------------------------------------------------
\input{endpages}

% -----------------------------------------------------------------------------
% DODATEK
% -----------------------------------------------------------------------------
\input{appendix}


\end{document}
